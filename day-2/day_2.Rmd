---
title: "day_2"
author: "Avery Richards"
date: "1/6/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(tidyverse)
library(tidytext)
library(viridis)

```



## Unsupervised methods

In this session, we'll cover unsupervised computational text analysis approaches. The central methods covered are TF-IDF and Topic Modeling. Both of these are common approachs in the social sciences and humanities.


```{r, message = F, warning = F}

music_revs <- read_delim("data/music_reviews.csv", 
                       delim = "\t")

```



```{r}

music_revs %>% select(body)

```


```{r}

music_revs %>% 
  group_by(genre) %>% 
  count(sort = TRUE)

```


```{r}

music_revs %>% 
  summary(score)


```

Who were the reviewers?


```{r}

music_revs %>% 
  group_by(critic) %>% 
  count(sort = TRUE)



```

And the artists?


```{r}

music_revs %>% 
  group_by(artist) %>% 
  count(sort = TRUE)


```

We can get the average score as follows:

```{r}

music_revs %>% 
  summarise(avg_score = mean(score))


```

Now we want to know the average score for each genre:

```{r}

music_revs %>% 
  group_by(genre) %>% 
  summarize(avg_score = mean(score)) %>% 
  arrange(desc(avg_score))


```

## Analyzing word and document frequency: tf-idf

```{r}

rev_words <- music_revs %>%
  select(body, genre) %>% 
  mutate(body = str_remove_all(body,'\\d+')) %>% 
  unnest_tokens(word, body) %>%
  count(genre, word, sort = TRUE)

rev_words %>% head(15)

```

```{r}

total_words <- rev_words %>% 
  group_by(genre) %>% 
  summarize(total = sum(n))

rev_words <- left_join(rev_words, total_words)

rev_words
```

```{r}

ggplot(rev_words, aes(n/total, fill = genre)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.07) +
  facet_wrap(~genre, ncol = 3, scales = "free_y")


```

Looking at the term frequencies, we've got very left skewed distributions among all genres, illustrating how in the text of the reviews, many words occur rarely and few, if any, words occur with that much frequently.


```{r}

freq_by_rank <- rev_words %>% 
 group_by(genre) %>% 
  summarise(n = n()) %>% 
   mutate(rank = row_number(), 
          `term frequency` = n/total) %>%
  ungroup()

freq_by_rank
```


```{r}

freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = genre)) + 
  geom_line(size = 1.1, alpha = 0.5, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()

```


```{r}

rank_subset <- freq_by_rank %>% 
  filter(rank < 500,
         rank > 10)

lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)


```


```{r}

freq_by_rank %>% 
  ggplot(aes(rank, `term frequency`, color = genre)) + 
  geom_abline(intercept = -0.62, slope = -1.1, 
              color = "gray50", linetype = 2) +
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()

```


```{r}

rev_tf_idf <- rev_words %>%
  bind_tf_idf(word, genre, n)


```

```{r}

rev_tf_idf %>%
  select(-total) %>%
  arrange(desc(tf_idf))


```


```{r}

library(forcats)

book_tf_idf %>%
  group_by(genre) %>%
  slice_max(tf_idf, n = 5) %>%
  ungroup() %>%
  ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill = genre)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~genre, ncol = 3, scales = "free") +
  labs(x = "tf-idf", y = NULL)

```


```{r}

phy_texts <- read_csv("data/classic_physics_texts.csv")

```


```{r}

phy_texts %>% select(text) %>% 
  na.omit()
```


```{r}

phy_texts %>% 
  group_by(author) %>% 
  summarise(text_lines = n())


```


```{r}

phy_texts_words <- phy_texts %>%
  select(text, author) %>% 
  unnest_tokens(word, text) %>%
  count(author, word, sort = TRUE)

phy_texts_words %>% head(15)

```


```{r}

total_words <- phy_texts_words %>% 
  group_by(author) %>% 
  summarize(total = sum(n))

phy_texts_words <- left_join(phy_texts_words, total_words)

phy_texts_words


```


```{r, warning=F}

ggplot(phy_texts_words, aes(n/total, fill = author)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.1) +
  facet_wrap(~author, ncol = 2, scales = "free_y")


```


```{r}

phy_texts_tf_idf <- phy_texts_words %>%
  bind_tf_idf(word, author, n) %>%
  mutate(author = factor(author, levels = c("Galilei, Galileo",
                                            "Huygens, Christiaan", 
                                            "Tesla, Nikola",
                                            "Einstein, Albert")))

phy_texts_tf_idf %>% 
  select(author, word, tf_idf) %>% 
    arrange(desc(tf_idf))

```


```{r}

phy_texts_tf_idf  %>% 
  group_by(author) %>% 
  slice_max(tf_idf, n = 15) %>% 
  ungroup() %>%
  mutate(word = reorder(word, tf_idf)) %>%
  ggplot(aes(tf_idf, word, fill = author)) +
  geom_col(show.legend = FALSE) +
  labs(x = "tf-idf", y = NULL) +
  facet_wrap(~author, ncol = 2, scales = "free")


```

Interesting results! There looks to be some noisy terms in our lineup. After digging about we learn that "AB", "AC", "RC‚Äù, are names of rays, angles,and shapes in Huygens' writing. We also recognize the terms "co" and "ordinate" right next to each other in Einsteins' graph. After acknowledging these findings, our next step is to clean up our dataset to make some meaningfull visualizations. 

```{r}



```
